{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e043e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba287a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.8</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex   bmi  children smoker     region  expenses\n",
       "0   19  female  27.9         0    yes  southwest  16884.92\n",
       "1   18    male  33.8         1     no  southeast   1725.55\n",
       "2   28    male  33.0         3     no  southeast   4449.46\n",
       "3   33    male  22.7         0     no  northwest  21984.47\n",
       "4   32    male  28.9         0     no  northwest   3866.86"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129bdec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "expenses    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preparation\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e28ecc",
   "metadata": {},
   "source": [
    "# The dataset has three columns with string values. Because machine learning models can take only numeric values, we need to replace those categorical string values with numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3b5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].replace({'female': 1, 'male': 2})\n",
    "df['smoker'] = df['smoker'].replace({'yes': 1, 'no': 2})\n",
    "df['region'] = df['region'].replace({'southwest': 1, 'southeast': 2, 'northwest': 3, 'northeast': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f75e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Input Features and Target Variable\n",
    "\n",
    "X = df.drop(columns = ['expenses'])\n",
    "y = df['expenses']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eaea4d",
   "metadata": {},
   "source": [
    "# Split the Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d23e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will put X, y that we previously defined, test_size of 0.25 which means \n",
    "# 25% of the data will be kept for testing purposes,s\n",
    "# and random_state of 1 (you can use any other integer as random_state).\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5cf74f",
   "metadata": {},
   "source": [
    "# Scaling the Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969250d",
   "metadata": {},
   "source": [
    "#It is a good practice to scale the data and bring them to the same range in Polynomial Regression.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58008f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a good practice to scale the data and bring them to the same range in Polynomial Regression.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1d91f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3587284607.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Model Development\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Model Development\n",
    "As Polynomial Regression is based on Linear Regression we need to import Linear Regression and Polynomial Features method. Model development has a bit extra step than Linear Regression.\n",
    "The first step is to call the PolynomialFeatures method with the degree of power.\n",
    "Fitting the input features to the PolynomialFeatures method for both training and testing data.\n",
    "Fitting the training input and output variables into the Polynomial Features method.\n",
    "Finally, when the data is ready, use the Linear Regression method to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc646606",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m poly\u001b[38;5;241m.\u001b[39mfit(X_poly_train, y_train)\n\u001b[0;32m      8\u001b[0m lin\u001b[38;5;241m.\u001b[39mfit(X_poly_train, y_train)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mLinearRegression\u001b[49m\n\u001b[0;32m     11\u001b[0m LinearRegression()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn.linear_model as lm\n",
    "lin = lm.LinearRegression()\n",
    "poly = PolynomialFeatures(degree=6)\n",
    "X_poly_train = poly.fit_transform(X_train_scaler)\n",
    "X_test_poly = poly.transform(X_test_scaler)\n",
    "poly.fit(X_poly_train, y_train)\n",
    "lin.fit(X_poly_train, y_train)\n",
    "\n",
    "LinearRegression\n",
    "LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d341f",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "We will evaluate the model using both training and testing data here. Starting with testing data, here is the predicted ‘charges’ for the test data:\n",
    "y_pred = lin.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dc20601",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculating the mean absolute error\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error\n\u001b[1;32m----> 4\u001b[0m mean_absolute_error(y_test, \u001b[43my_pred\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculating the mean absolute error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca3218a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2055.6724950149555"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean absolute error looks pretty big! Now see how the model performs on training data:\n",
    "\n",
    "y_pred_train = lin.predict(X_poly_train)\n",
    "mean_absolute_error(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae90688",
   "metadata": {},
   "source": [
    "# On training, data mean absolute error is much smaller than the mean absolute error on the test data. That means the model learned the training data so well that it can only perform well on training data. When we try some new data model performs poorly. This is called overfitting.\n",
    "Solving Overfitting Problem\n",
    "Solving the overfitting problem starts with hyperparameter tuning. We should try different hyperparameters to find the optimum values where the model performs well on both training and testing data. This was a simple model. We have only one hyperparameter here which is the degree in the PolynomialFeatures method. Before, we used the degree as 6, now we will try with the degree of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53faca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly_train = poly.fit_transform(X_train_scaler)\n",
    "X_test_poly = poly.transform(X_test_scaler)\n",
    "poly.fit(X_poly_train, y_train)\n",
    "lin = lm.LinearRegression()\n",
    "lin.fit(X_poly_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c2f2f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2724.290328358209"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s test the mean absolute error on training and test data now. Starting with the test data.\n",
    "\n",
    "y_pred = lin.predict(X_test_poly)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c8df3",
   "metadata": {},
   "source": [
    "# The mean absolute error was lowered by a huge margin than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf115a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2725.598554336989"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how it works on the training data:\n",
    "\n",
    "y_pred_train = lin.predict(X_poly_train)\n",
    "mean_absolute_error(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b041410",
   "metadata": {},
   "source": [
    "# Conclusion - The mean absolute error on training data and test data are so close: 2819 and 2818 respectively. This is perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e35a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
